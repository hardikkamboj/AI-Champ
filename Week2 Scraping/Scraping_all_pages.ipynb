{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observing how the next urls are \n",
    "# then storing all the urls in a list (except the first)\n",
    "urls = ['http://books.toscrape.com/catalogue/page-' + str(i) + '.html' for i in range(2,51)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first url \n",
    "url = ['http://books.toscrape.com/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding all the urls in a list\n",
    "url.extend(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making sure it contains all the 50 pages\n",
    "len(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "ratings = []\n",
    "availabilities = []\n",
    "prices = []\n",
    "images = []\n",
    "\n",
    "# iterating through each page\n",
    "for page in url:\n",
    "    result = requests.get(page)\n",
    "    src = result.content\n",
    "    soup = BeautifulSoup(src, 'html.parser')\n",
    "    for link in soup.find_all('li',class_ = 'col-xs-6 col-sm-4 col-md-3 col-lg-3'):\n",
    "        name = link.find('h3').a['title']\n",
    "        rating = link.find('p').get('class')[1]\n",
    "        price = link.find('div',class_ = 'product_price').p.text\n",
    "        avlb = link.find('div',class_ = 'product_price').find('p',class_ = 'instock availability').text\n",
    "        img = link.find('img').attrs['src']\n",
    "\n",
    "        names.append(name)\n",
    "        ratings.append(rating)\n",
    "        availabilities.append(avlb)\n",
    "        prices.append(price)\n",
    "        images.append(img)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Name':names,'Rating':ratings,'Availability':availabilities,'Price':prices,'Image_src':images})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Availability</th>\n",
       "      <th>Price</th>\n",
       "      <th>Image_src</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Light in the Attic</td>\n",
       "      <td>Three</td>\n",
       "      <td>\\n\\n    \\n        In stock\\n    \\n</td>\n",
       "      <td>£51.77</td>\n",
       "      <td>media/cache/2c/da/2cdad67c44b002e7ead0cc35693c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tipping the Velvet</td>\n",
       "      <td>One</td>\n",
       "      <td>\\n\\n    \\n        In stock\\n    \\n</td>\n",
       "      <td>£53.74</td>\n",
       "      <td>media/cache/26/0c/260c6ae16bce31c8f8c95daddd9f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Soumission</td>\n",
       "      <td>One</td>\n",
       "      <td>\\n\\n    \\n        In stock\\n    \\n</td>\n",
       "      <td>£50.10</td>\n",
       "      <td>media/cache/3e/ef/3eef99c9d9adef34639f51066202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sharp Objects</td>\n",
       "      <td>Four</td>\n",
       "      <td>\\n\\n    \\n        In stock\\n    \\n</td>\n",
       "      <td>£47.82</td>\n",
       "      <td>media/cache/32/51/3251cf3a3412f53f339e42cac213...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sapiens: A Brief History of Humankind</td>\n",
       "      <td>Five</td>\n",
       "      <td>\\n\\n    \\n        In stock\\n    \\n</td>\n",
       "      <td>£54.23</td>\n",
       "      <td>media/cache/be/a5/bea5697f2534a2f86a3ef27b5a8c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Name Rating  \\\n",
       "0                   A Light in the Attic  Three   \n",
       "1                     Tipping the Velvet    One   \n",
       "2                             Soumission    One   \n",
       "3                          Sharp Objects   Four   \n",
       "4  Sapiens: A Brief History of Humankind   Five   \n",
       "\n",
       "                         Availability   Price  \\\n",
       "0  \\n\\n    \\n        In stock\\n    \\n  £51.77   \n",
       "1  \\n\\n    \\n        In stock\\n    \\n  £53.74   \n",
       "2  \\n\\n    \\n        In stock\\n    \\n  £50.10   \n",
       "3  \\n\\n    \\n        In stock\\n    \\n  £47.82   \n",
       "4  \\n\\n    \\n        In stock\\n    \\n  £54.23   \n",
       "\n",
       "                                           Image_src  \n",
       "0  media/cache/2c/da/2cdad67c44b002e7ead0cc35693c...  \n",
       "1  media/cache/26/0c/260c6ae16bce31c8f8c95daddd9f...  \n",
       "2  media/cache/3e/ef/3eef99c9d9adef34639f51066202...  \n",
       "3  media/cache/32/51/3251cf3a3412f53f339e42cac213...  \n",
       "4  media/cache/be/a5/bea5697f2534a2f86a3ef27b5a8c...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n",
    "# it has 1000 rows, therefore all the pages are scraped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving in a csv file\n",
    "df.to_csv('all_pages_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scraping",
   "language": "python",
   "name": "scraping"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
