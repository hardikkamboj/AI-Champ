{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Cifar 10 with Transfer Learning\nI have implemented cifar 10 with ANN, and CNN earlier, and in this notebook i will be trying to implement it using transfer learning and see how the results vary from my previous attempts <br> <br>\nYou can check the previous notebooks from here - \n- [Cifar 10 with ANN](https://www.kaggle.com/kambojharyana/playing-around-with-cifar-and-ann)\n- [Cifar 10 with CNN, using Data Augementation](https://www.kaggle.com/kambojharyana/cifar10-with-cnn)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# load the standart libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Import keras functions\n\nfrom keras import Sequential\n\nfrom keras.applications import VGG19,ResNet50\n\n'Import the datagenerator to augment images'\nfrom keras.preprocessing.image import ImageDataGenerator\n\nfrom keras.optimizers import SGD,Adam\nfrom keras.callbacks import ReduceLROnPlateau\n\nfrom keras.layers import Flatten,Dense,BatchNormalization,Activation,Dropout\n\n'Import to_categorical from the keras utils package to one hot encode the labels'\nfrom keras.utils import to_categorical","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import dataset\nfrom keras.datasets import cifar10\n\n# load the dataset into train and test from cifar10 object\n(X_train,y_train),(X_test,y_test)=cifar10.load_data()","execution_count":3,"outputs":[{"output_type":"stream","text":"Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n170500096/170498071 [==============================] - 2s 0us/step\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# view the dimensions of train and test data to ensure everything is going fine \nprint(X_train.shape,y_train.shape)\nprint(X_test.shape,y_test.shape)","execution_count":4,"outputs":[{"output_type":"stream","text":"(50000, 32, 32, 3) (50000, 1)\n(10000, 32, 32, 3) (10000, 1)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"The data visualization part has been done in the previos two notebooks, here, we will jump straight into model training, before done some preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"num_classes = 10\ny_train = to_categorical(y_train,num_classes)\ny_test = to_categorical(y_test,num_classes)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking the dimensions again, to verify the change\nprint(X_train.shape,y_train.shape)\nprint(X_test.shape,y_test.shape)\n# the dimensions of the labels have now changed. ","execution_count":6,"outputs":[{"output_type":"stream","text":"(50000, 32, 32, 3) (50000, 10)\n(10000, 32, 32, 3) (10000, 10)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Model "},{"metadata":{},"cell_type":"markdown","source":"The preprocessing part is done, now, before defining the transfer learning model, we will first define the data augmentation object, and train it on the training data only. We will be using data augmentation of training data only. "},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator = ImageDataGenerator(\n                                    rotation_range=2, \n                                    horizontal_flip=True,\n                                    zoom_range=.1 )\n\n\n#now fit it to train data \ntrain_generator.fit(X_train)","execution_count":7,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Building model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# will be using VGG19, make sure the input shape is same as that of CIFAR10\nbase_model = VGG19(include_top=False,weights='imagenet',input_shape=(32,32,3),classes=y_train.shape[1])","execution_count":8,"outputs":[{"output_type":"stream","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n80142336/80134624 [==============================] - 1s 0us/step\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# use the base model, and add more layers to it. \nmodel= Sequential()\nmodel.add(base_model) #Adds the base model (in this case vgg19 to model)\nmodel.add(Flatten()) \n\n# add some dense layers \nmodel.add(Dense(1024,activation=('relu')))\nmodel.add(Dense(512,activation=('relu'))) \nmodel.add(Dense(256,activation=('relu'))) \nmodel.add(Dropout(.3)) #Adding a dropout layer that will randomly drop 30% of the weights\nmodel.add(Dense(128,activation=('relu')))\nmodel.add(Dropout(.2)) #Adding a dropout layer that will randomly drop 20% of the weights\nmodel.add(Dense(10,activation=('softmax'))) #This is the classification layer\n","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model summay \nmodel.summary()","execution_count":10,"outputs":[{"output_type":"stream","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nvgg19 (Functional)           (None, 1, 1, 512)         20024384  \n_________________________________________________________________\nflatten (Flatten)            (None, 512)               0         \n_________________________________________________________________\ndense (Dense)                (None, 1024)              525312    \n_________________________________________________________________\ndense_1 (Dense)              (None, 512)               524800    \n_________________________________________________________________\ndense_2 (Dense)              (None, 256)               131328    \n_________________________________________________________________\ndropout (Dropout)            (None, 256)               0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 128)               32896     \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 128)               0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 10)                1290      \n=================================================================\nTotal params: 21,240,010\nTrainable params: 21,240,010\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# compile the model \nmodel.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 64\nepochs = 50\nhistory = model.fit_generator(train_generator.flow(X_train,y_train,batch_size=batch_size),\n                      epochs=epochs,\n                      steps_per_epoch=X_train.shape[0]//batch_size,\n                      validation_data=(X_test,y_test))","execution_count":12,"outputs":[{"output_type":"stream","text":"Epoch 1/50\n781/781 [==============================] - 44s 56ms/step - loss: 2.0582 - accuracy: 0.1915 - val_loss: 1.8485 - val_accuracy: 0.2409\nEpoch 2/50\n781/781 [==============================] - 44s 56ms/step - loss: 1.8229 - accuracy: 0.2520 - val_loss: 1.7105 - val_accuracy: 0.3252\nEpoch 3/50\n781/781 [==============================] - 44s 56ms/step - loss: 1.6597 - accuracy: 0.3452 - val_loss: 1.5429 - val_accuracy: 0.3793\nEpoch 4/50\n781/781 [==============================] - 44s 57ms/step - loss: 1.6066 - accuracy: 0.3716 - val_loss: 1.4968 - val_accuracy: 0.4077\nEpoch 5/50\n781/781 [==============================] - 44s 56ms/step - loss: 1.4737 - accuracy: 0.4223 - val_loss: 1.4448 - val_accuracy: 0.4321\nEpoch 6/50\n781/781 [==============================] - 43s 55ms/step - loss: 1.3379 - accuracy: 0.4836 - val_loss: 1.2239 - val_accuracy: 0.5319\nEpoch 7/50\n781/781 [==============================] - 44s 56ms/step - loss: 1.2888 - accuracy: 0.5257 - val_loss: 1.1839 - val_accuracy: 0.5718\nEpoch 8/50\n781/781 [==============================] - 45s 57ms/step - loss: 1.1972 - accuracy: 0.5751 - val_loss: 1.1541 - val_accuracy: 0.5810\nEpoch 9/50\n781/781 [==============================] - 43s 55ms/step - loss: 1.1620 - accuracy: 0.5985 - val_loss: 1.2286 - val_accuracy: 0.5940\nEpoch 10/50\n781/781 [==============================] - 44s 56ms/step - loss: 1.1153 - accuracy: 0.6187 - val_loss: 1.0227 - val_accuracy: 0.6527\nEpoch 11/50\n781/781 [==============================] - 45s 58ms/step - loss: 1.0834 - accuracy: 0.6341 - val_loss: 1.1104 - val_accuracy: 0.6204\nEpoch 12/50\n781/781 [==============================] - 44s 56ms/step - loss: 1.1430 - accuracy: 0.5942 - val_loss: 1.0439 - val_accuracy: 0.6430\nEpoch 13/50\n781/781 [==============================] - 43s 55ms/step - loss: 1.0546 - accuracy: 0.6444 - val_loss: 1.0123 - val_accuracy: 0.6623\nEpoch 14/50\n781/781 [==============================] - 45s 58ms/step - loss: 1.0521 - accuracy: 0.6561 - val_loss: 1.1788 - val_accuracy: 0.6306\nEpoch 15/50\n781/781 [==============================] - 44s 56ms/step - loss: 1.1804 - accuracy: 0.6062 - val_loss: 1.0195 - val_accuracy: 0.6518\nEpoch 16/50\n781/781 [==============================] - 43s 56ms/step - loss: 0.9765 - accuracy: 0.6635 - val_loss: 1.0250 - val_accuracy: 0.6527\nEpoch 17/50\n781/781 [==============================] - 43s 55ms/step - loss: 0.9385 - accuracy: 0.6871 - val_loss: 0.9345 - val_accuracy: 0.6900\nEpoch 18/50\n781/781 [==============================] - 44s 57ms/step - loss: 0.9103 - accuracy: 0.7028 - val_loss: 0.8645 - val_accuracy: 0.7215\nEpoch 19/50\n781/781 [==============================] - 44s 57ms/step - loss: 1.1317 - accuracy: 0.6202 - val_loss: 1.6893 - val_accuracy: 0.2927\nEpoch 20/50\n781/781 [==============================] - 42s 54ms/step - loss: 1.3206 - accuracy: 0.4963 - val_loss: 1.3084 - val_accuracy: 0.5152\nEpoch 21/50\n781/781 [==============================] - 44s 56ms/step - loss: 1.0078 - accuracy: 0.6453 - val_loss: 0.8983 - val_accuracy: 0.7043\nEpoch 22/50\n781/781 [==============================] - 45s 57ms/step - loss: 0.8713 - accuracy: 0.7097 - val_loss: 0.9176 - val_accuracy: 0.6944\nEpoch 23/50\n781/781 [==============================] - 44s 56ms/step - loss: 0.8359 - accuracy: 0.7268 - val_loss: 0.8516 - val_accuracy: 0.7194\nEpoch 24/50\n781/781 [==============================] - 42s 54ms/step - loss: 1.0294 - accuracy: 0.6486 - val_loss: 1.7568 - val_accuracy: 0.3045\nEpoch 25/50\n781/781 [==============================] - 44s 57ms/step - loss: 1.1365 - accuracy: 0.5977 - val_loss: 0.9837 - val_accuracy: 0.6864\nEpoch 26/50\n781/781 [==============================] - 44s 56ms/step - loss: 0.8065 - accuracy: 0.7379 - val_loss: 0.8167 - val_accuracy: 0.7369\nEpoch 27/50\n781/781 [==============================] - 43s 55ms/step - loss: 0.7405 - accuracy: 0.7638 - val_loss: 0.9778 - val_accuracy: 0.7016\nEpoch 28/50\n781/781 [==============================] - 43s 55ms/step - loss: 0.7299 - accuracy: 0.7671 - val_loss: 0.7601 - val_accuracy: 0.7619\nEpoch 29/50\n781/781 [==============================] - 44s 56ms/step - loss: 0.6723 - accuracy: 0.7887 - val_loss: 0.7580 - val_accuracy: 0.7698\nEpoch 30/50\n781/781 [==============================] - 43s 55ms/step - loss: 0.7059 - accuracy: 0.7743 - val_loss: 0.7380 - val_accuracy: 0.7705\nEpoch 31/50\n781/781 [==============================] - 43s 55ms/step - loss: 0.8250 - accuracy: 0.7290 - val_loss: 0.8003 - val_accuracy: 0.7425\nEpoch 32/50\n781/781 [==============================] - 44s 56ms/step - loss: 0.6694 - accuracy: 0.7879 - val_loss: 0.7101 - val_accuracy: 0.7835\nEpoch 33/50\n781/781 [==============================] - 44s 56ms/step - loss: 0.6520 - accuracy: 0.7960 - val_loss: 0.7761 - val_accuracy: 0.7596\nEpoch 34/50\n781/781 [==============================] - 45s 57ms/step - loss: 0.6641 - accuracy: 0.7907 - val_loss: 0.7831 - val_accuracy: 0.7527\nEpoch 35/50\n781/781 [==============================] - 42s 54ms/step - loss: 0.6029 - accuracy: 0.8075 - val_loss: 0.6760 - val_accuracy: 0.7935\nEpoch 36/50\n781/781 [==============================] - 44s 56ms/step - loss: 0.7319 - accuracy: 0.7633 - val_loss: 0.7979 - val_accuracy: 0.7388\nEpoch 37/50\n781/781 [==============================] - 44s 56ms/step - loss: 1.2318 - accuracy: 0.5965 - val_loss: 0.8603 - val_accuracy: 0.7489\nEpoch 38/50\n781/781 [==============================] - 43s 55ms/step - loss: 0.7030 - accuracy: 0.7758 - val_loss: 0.7521 - val_accuracy: 0.7847\nEpoch 39/50\n781/781 [==============================] - 43s 55ms/step - loss: 0.5733 - accuracy: 0.8184 - val_loss: 0.6889 - val_accuracy: 0.7873\nEpoch 40/50\n781/781 [==============================] - 44s 57ms/step - loss: 0.5445 - accuracy: 0.8274 - val_loss: 0.7146 - val_accuracy: 0.7937\nEpoch 41/50\n781/781 [==============================] - 44s 56ms/step - loss: 0.5498 - accuracy: 0.8265 - val_loss: 0.7335 - val_accuracy: 0.7910\nEpoch 42/50\n781/781 [==============================] - 42s 54ms/step - loss: 0.5571 - accuracy: 0.8250 - val_loss: 0.6703 - val_accuracy: 0.8047\nEpoch 43/50\n781/781 [==============================] - 44s 56ms/step - loss: 0.5251 - accuracy: 0.8349 - val_loss: 0.6577 - val_accuracy: 0.8006\nEpoch 44/50\n781/781 [==============================] - 43s 56ms/step - loss: 0.4989 - accuracy: 0.8443 - val_loss: 0.7213 - val_accuracy: 0.7929\nEpoch 45/50\n781/781 [==============================] - 44s 56ms/step - loss: 1.0135 - accuracy: 0.6831 - val_loss: 1.6906 - val_accuracy: 0.3467\nEpoch 46/50\n781/781 [==============================] - 43s 55ms/step - loss: 0.9577 - accuracy: 0.6609 - val_loss: 0.7550 - val_accuracy: 0.7663\nEpoch 47/50\n781/781 [==============================] - 43s 56ms/step - loss: 0.5762 - accuracy: 0.8106 - val_loss: 0.6985 - val_accuracy: 0.7904\nEpoch 48/50\n781/781 [==============================] - 44s 57ms/step - loss: 0.5943 - accuracy: 0.8069 - val_loss: 1.9725 - val_accuracy: 0.2844\nEpoch 49/50\n781/781 [==============================] - 43s 55ms/step - loss: 0.8578 - accuracy: 0.7094 - val_loss: 0.7001 - val_accuracy: 0.7854\nEpoch 50/50\n781/781 [==============================] - 44s 56ms/step - loss: 0.4976 - accuracy: 0.8415 - val_loss: 0.6757 - val_accuracy: 0.7978\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate(X_test,y_test)","execution_count":13,"outputs":[{"output_type":"stream","text":"313/313 [==============================] - 3s 9ms/step - loss: 0.6757 - accuracy: 0.7978\n","name":"stdout"},{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"[0.6757317185401917, 0.7978000044822693]"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"So, model with transfer learning is having around 80% of accuracy on test data, and around 84% of accuracy on train data with augmentation. "},{"metadata":{},"cell_type":"markdown","source":"Still, there are many things that we can try from here, like keeping the VGG layers fixed, adding Batch Normalization, data normalization, playing around with the final layers of the network and all. Lets cover that in the future. "}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}